# ğŸ§ª Final Testing Guide - Report Generation

## Prerequisites Check

Before testing, ensure:
- âœ… Backend server is running (`npm start` in `backend/`)
- âœ… Frontend is running (`npm start` in `frontend/`)
- âœ… MongoDB is connected
- âœ… You have at least one **completed project** (100% progress)

---

## ğŸ¯ Test Scenario: Generate Report for Completed Project

### Step 1: Select Test Project

**Requirements:**
- Project completion: **100%**
- Has submitted responses from evaluators
- Has at least one ethical tension (optional but recommended)

**Best test project:**
- "test case 2" or any project with:
  - Multiple evaluators (2+)
  - Multiple roles (legal-expert, etc.)
  - General questions + role-specific questions answered

---

### Step 2: Open Backend Console

**Keep this terminal visible while testing!**

You'll see critical debug logs here:

```powershell
cd backend
npm start

# Wait for:
# Server running on port 3000
# MongoDB connected...
```

---

### Step 3: Generate Report

1. **Browser:** Open `http://localhost:3001` (or your frontend port)
2. **Login** as Admin
3. **Navigate** to project list
4. **Select** a completed project
5. **Click** "Generate Report" button
6. **Wait** 30-60 seconds (report generation takes time)

---

### Step 4: Watch Console Logs â­ CRITICAL

While report generates, **look for these patterns** in backend console:

#### âœ… SUCCESS Pattern:

```
ğŸ“ˆ Building report metrics for charts...
ğŸ“Š [DEBUG buildReportMetrics] Found 6 Score documents (all questionnaires)

ğŸ” [DEBUG buildReportMetrics] Mapping 7 principles to byPrincipleOverall
  ğŸ“Š TRANSPARENCY: Found 2 score document(s) with data
    Risk values: [2.5, 2.3]
    âœ… Populated: avgRisk=2.40, count=2, topDrivers=5
  ğŸ“Š ACCOUNTABILITY: Found 2 score document(s) with data
    Risk values: [1.8, 2.0]
    âœ… Populated: avgRisk=1.90, count=2, topDrivers=3
  ... (for all 7 principles)

âœ… [DEBUG buildReportMetrics] byPrincipleOverall populated: 7 principles
   TRANSPARENCY=2.40, ACCOUNTABILITY=1.90, TECHNICAL ROBUSTNESS & SAFETY=2.10, ...

ğŸ” [DEBUG reportController] Passing data to chart generation:
   scoring.byPrincipleOverall exists: true
   Principle count: 7
   Principle keys: TRANSPARENCY, HUMAN AGENCY & OVERSIGHT, TECHNICAL ROBUSTNESS & SAFETY, ...
   "TRANSPARENCY": { isNull: false, fields: 'avgScore,avg,risk,erc,min,max,count,answeredCount,riskLabel,...', risk: 2.4, avg: 2.4, erc: 2.4 }

ğŸ“Š Generating charts using Chart Contract system...
ğŸ” [DEBUG generateAllCharts] Received scoring object:
   exists: true, hasByPrincipleOverall: true, principleCount: 7, principleKeys: [...]
   Sample principle "TRANSPARENCY": { isNull: false, fields: ['avgScore','avg','risk','erc',...], risk: 2.4, avg: 2.4, erc: 2.4 }

ğŸ“Š Generating principleBarChart with 7 non-null principles...
âœ… principleBarChart generated successfully

ğŸ“Š Generating principleEvaluatorHeatmap...
âœ… principleEvaluatorHeatmap generated successfully

âœ… Chart Contract system generated 2 chart(s)

ğŸ“Š Building top risk drivers table...
ğŸ“Š [buildTopRiskDriversTable] Extracted 15 drivers from scores.byPrinciple
âœ… Built top risk drivers table with 5 drivers

âœ… Converted 2 chart(s) to data URIs for HTML template

ğŸ¤– Calling Gemini API for narrative generation...
âœ… Report narrative generated (5234 chars)

âœ… HTML report generated (45123 chars)
ğŸ” DEBUG: img tags with data URIs in HTML: 2 (expected: 2)

âœ… Report generation complete!
```

#### âŒ FAILURE Patterns to Watch For:

**Pattern A: No Data**
```
âŒ CRITICAL: byPrincipleOverall is EMPTY! Charts will not render.
   Scores count: 0
```
â†’ **Problem:** No Score documents in MongoDB  
â†’ **Fix Needed:** Run scoring service

**Pattern B: Data Lost**
```
âœ… byPrincipleOverall populated: 7 principles
...
âŒ reportMetrics.scoring.byPrincipleOverall is MISSING or EMPTY!
```
â†’ **Problem:** Data not passed to chart generation  
â†’ **Share console logs for diagnosis**

**Pattern C: Chart Generation Failed**
```
ğŸ“Š Generating principleBarChart with 7 non-null principles...
âŒ principleBarChart generation failed: ...
```
â†’ **Problem:** Chart rendering error  
â†’ **Share error message**

---

### Step 5: Download & Inspect PDF

Once generation completes:

1. **Download** the generated PDF
2. **Open** in PDF viewer (Adobe, Chrome, etc.)
3. **Verify** using checklist below

---

## âœ… PDF Verification Checklist

### Section 1: Executive Summary (First Page)

- [ ] **Overall Risk Score** appears (e.g., "1.85 / 4.0")
- [ ] **Risk Classification** appears (e.g., "Low Risk" or "Medium Risk")
- [ ] **Risk label is consistent** (not contradictory)
- [ ] **Evaluator counts** appear (e.g., "2/5 evaluators submitted")
- [ ] **7 Ethical principles** mentioned with ERC scores

**Example (Good):**
```
Overall Ethical Risk: 1.85 / 4.0 (Low Risk)
Evaluation Coverage: 2 of 5 assigned evaluators submitted responses
```

**Example (Bad - Report this!):**
```
Overall Risk: 0.91 (LOW RISK)  â† Contradictory!
Later: Score 0.91 = Minimal Risk
```

---

### Section 2: Dashboard Summary

#### Charts - CRITICAL TEST â­

**Principle Bar Chart:**
- [ ] **Chart IMAGE appears** (not "Chart Not Available" text)
- [ ] **7 colored bars** visible (one per principle)
- [ ] **Y-axis scale**: 0 to 4
- [ ] **Bars have different heights** (showing actual data)
- [ ] **Legend/Threshold guide** appears below chart

**Example (Good):**
```
[VISUAL BAR CHART HERE showing 7 bars of varying heights from 0-4]
Scale 0â€“4 (ERC Risk Interpretation)
0.0: MINIMAL/NO RISK
1.0: LOW RISK
...
```

**Example (Bad - Report this!):**
```
âš ï¸ Chart Not Available: No principle score data available for visualization.
```

**Role Ã— Principle Heatmap:**
- [ ] **Chart IMAGE appears** (not "Chart Not Available")
- [ ] **Matrix/grid** visible with rows (evaluators) and columns (principles)
- [ ] **Color gradient** showing risk levels
- [ ] **Legend** explaining colors

---

### Section 3: Top Risk Drivers

**Top 5 Questions Table:**
- [ ] **Table appears** (not empty)
- [ ] **5 rows** (or fewer if <5 questions)
- [ ] Each row has:
  - [ ] **Question text** (actual question, not just ID)
  - [ ] **Principle name** (e.g., "TRANSPARENCY")
  - [ ] **ERC score** (numeric value 0-4)
  - [ ] **Answer snippet** (text excerpt, 50-200 chars)
  - [ ] **Role** who answered (e.g., "legal-expert")

**Example (Good):**
```
| Question | Principle | ERC | Role | Answer |
|----------|-----------|-----|------|--------|
| Does the system provide explanations for decisions? | TRANSPARENCY | 2.4 | legal-expert | "The system provides basic explanations but lacks detail for complex cases..." |
```

**Example (Bad - Report this!):**
```
Top Risk Drivers
No drivers computed.
```

OR

```
| Question | Principle | ERC | Role | Answer |
|----------|-----------|-----|------|--------|
| (empty table) |
```

---

### Section 4: Ethical Tensions

**Tension Table:**
- [ ] **Tensions listed** (if any exist in project)
- [ ] For each tension:
  - [ ] **Created By**: Shows **real name** (e.g., "Dr. Sarah Johnson")
    - âŒ BAD: User ID like "507f1f77bcf86cd799439011"
    - âŒ BAD: "unknown"
  - [ ] **Evidence Types**: Shows **list** (e.g., "Policy, Test Report")
    - âŒ BAD: "N/A"
  - [ ] **Claim**: Shows **actual claim** or clean placeholder "â€”"
    - âŒ BAD: "Not provided"
  - [ ] **Review State**: Shows normalized state (e.g., "UnderReview", "Accepted")
  - [ ] **Severity**: Shows level (Low/Medium/High/Critical)

**Example (Good):**
```
Tension 1: TRANSPARENCY vs PRIVACY & DATA GOVERNANCE
Created By: Dr. Sarah Johnson
Severity: Medium
Claim: Explaining AI decisions requires disclosing sensitive data.
Evidence Types: Policy, Test Report
Review State: UnderReview
Consensus: 75% agree
```

**Example (Bad - Report this!):**
```
Created By: 507f1f77bcf86cd799439011  â† User ID!
Evidence Types: N/A                    â† Not informative!
Claim: Not provided                    â† Ugly!
```

---

### Section 5: Methodology & Appendix

- [ ] **ERC methodology explained**
- [ ] **Risk scale thresholds documented** (0-4 scale)
- [ ] **Evaluator list** appears
- [ ] **Evaluator counts consistent** with Executive Summary

---

## ğŸ“Š Console Log Collection

If ANY verification fails, collect these logs:

### Critical Logs to Copy:

```powershell
# Search in console for these patterns and copy ALL output:

1. "[DEBUG buildReportMetrics]" - Shows data extraction
2. "[DEBUG reportController]" - Shows data passing to charts
3. "[DEBUG generateAllCharts]" - Shows chart generation
4. "âŒ CRITICAL" - Critical errors
5. "âŒ Error" - All errors
6. "[buildTopRiskDriversTable]" - Top drivers status
```

**How to share:**
1. Copy entire console output from "Building report metrics" to "Report generation complete"
2. Save to a text file
3. Share the relevant sections

---

## ğŸ› Common Issues & Solutions

### Issue 1: "Chart Not Available"

**Symptoms:**
- PDF shows text instead of chart image
- Console shows: `No principle data available`

**Diagnosis:**
```
Look for:
âœ… [DEBUG buildReportMetrics] byPrincipleOverall populated: X principles
```

**If X = 0:**
- No Score documents exist
- Run: `db.scores.find({ projectId: ObjectId("YOUR_PROJECT_ID") }).count()` in MongoDB
- If 0, scores need to be computed

**If X > 0:**
- Data exists but not reaching charts
- Share console logs

---

### Issue 2: Top Drivers Empty

**Symptoms:**
- PDF shows "No drivers computed" or empty table

**Diagnosis:**
```
Look for:
ğŸ“Š [buildTopRiskDriversTable] Extracted X drivers
```

**If X = 0:**
- Fallback logic will compute from responses
- Look for: `âš ï¸ No topDrivers in scores, computing from responses...`
- If still 0, no responses exist

---

### Issue 3: Inconsistent Evaluator Counts

**Symptoms:**
- Executive Summary says "2/5"
- Dashboard says "2/6"
- Appendix says "6 evaluators"

**Diagnosis:**
```
Look for:
ğŸ“Š [computeParticipation] assignedCount=X, submittedCount=Y
```

**These should match across all report sections**

---

### Issue 4: Risk Label Contradictions

**Symptoms:**
- Score 0.91 shows "LOW" in one place, "Minimal" in another

**Should now be fixed!** All places should show "Minimal Risk" for 0.91.

If still inconsistent, report it!

---

## ğŸ“ Test Report Template

**Please fill this out and share:**

```
=== TEST RESULTS ===

Project Tested: [project name]
Completion: [100%]
Evaluators: [2/5 submitted]

CHARTS:
- Principle Bar Chart: [âœ… RENDERS / âŒ "Chart Not Available"]
- Role Ã— Principle Heatmap: [âœ… RENDERS / âŒ "Chart Not Available"]

TOP DRIVERS:
- Table populated: [âœ… YES (5 rows) / âŒ NO (empty)]
- Has answer snippets: [âœ… YES / âŒ NO]

TENSION TABLE:
- Created By format: [âœ… Real names / âŒ User IDs / âŒ "unknown"]
- Evidence Types format: [âœ… "Policy, Test" / âŒ "N/A"]
- Claim format: [âœ… Text or "â€”" / âŒ "Not provided"]

RISK LABELS:
- Consistent: [âœ… YES / âŒ NO - provide examples]

EVALUATOR COUNTS:
- Consistent: [âœ… YES / âŒ NO - provide numbers]

CONSOLE LOGS:
- Any âŒ CRITICAL errors: [YES/NO - if yes, paste below]
- Any âŒ Error messages: [YES/NO - if yes, paste below]

OVERALL:
- Report Quality: [EXCELLENT / GOOD / ISSUES FOUND]

LOGS (if issues found):
[Paste relevant console sections here]
```

---

## ğŸ‰ Success Criteria

Report is **EXCELLENT** if:
- âœ… All charts render (no "Not Available")
- âœ… Top drivers table has 5 rows with snippets
- âœ… Tension table shows real names and evidence types
- âœ… Risk labels consistent throughout
- âœ… Evaluator counts match everywhere
- âœ… No âŒ CRITICAL or âŒ Error in console

Report has **MINOR ISSUES** if:
- âœ… Charts render but tension table has some "N/A"
- âœ… Top drivers populated but <5 rows
- âš ï¸ One or two minor inconsistencies

Report **NEEDS FIXES** if:
- âŒ Charts show "Not Available"
- âŒ Top drivers empty
- âŒ Multiple contradictions

---

## ğŸš€ Next Steps

**If EXCELLENT:**
ğŸ‰ All done! Report generation is working perfectly!

**If MINOR ISSUES:**
ğŸ“ Report the issues, we can polish further

**If NEEDS FIXES:**
ğŸ” Share console logs, we'll debug together

---

**Ready to test? Start with Step 1!** ğŸ§ª

